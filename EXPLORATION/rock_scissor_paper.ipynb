{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "declared-librarian",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "relevant-booking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 레이어의 개수 :  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 110, 110, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 55, 55, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 53, 53, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                692256    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 697,443\n",
      "Trainable params: 697,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3, 3), activation = 'relu', input_shape = (112, 112, 3)))\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "print(\"Model에 추가된 레이어의 개수 : \", len(model.layers))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-female",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 + Resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dried-hearts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  images to be resized.\n",
      "500  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "500  images to be resized.\n",
      "500  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "500  images to be resized.\n",
      "500  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 112x112 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(112,112)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chubby-innocent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터의 이미지 개수는 1500 입니다.\n",
      "x_train shape: (1500, 112, 112, 3)\n",
      "y_train shape: (1500,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=1500):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=112\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"데이터의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-sector",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seven-grant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "47/47 [==============================] - 5s 51ms/step - loss: 1.2115 - accuracy: 0.4230\n",
      "Epoch 2/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.7106 - accuracy: 0.7092\n",
      "Epoch 3/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3978 - accuracy: 0.8648\n",
      "Epoch 4/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.2850 - accuracy: 0.8935\n",
      "Epoch 5/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.1780 - accuracy: 0.9463\n",
      "Epoch 6/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.1377 - accuracy: 0.9603\n",
      "Epoch 7/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.1125 - accuracy: 0.9642\n",
      "Epoch 8/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0794 - accuracy: 0.9829\n",
      "Epoch 9/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0564 - accuracy: 0.9872\n",
      "Epoch 10/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0508 - accuracy: 0.9887\n",
      "Epoch 11/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0374 - accuracy: 0.9937\n",
      "Epoch 12/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0349 - accuracy: 0.9936\n",
      "Epoch 13/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0533 - accuracy: 0.9847\n",
      "Epoch 14/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0534 - accuracy: 0.9848\n",
      "Epoch 15/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0430 - accuracy: 0.9920\n",
      "Epoch 16/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0200 - accuracy: 0.9974\n",
      "Epoch 17/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0107 - accuracy: 0.9984\n",
      "Epoch 18/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0093 - accuracy: 0.9984\n",
      "Epoch 19/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0124 - accuracy: 0.9972\n",
      "Epoch 20/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.0012 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f299c1dcd90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-correspondence",
   "metadata": {},
   "source": [
    "# 얼마나 잘 만들었는지 확인하기(테스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "injured-tactics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape : (300, 112, 112, 3)\n",
      "y_test shape : (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_datas(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=112\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "def resize_image(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 112x112 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(112,112)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_image(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_image(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_image(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "image_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test) = load_datas(image_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape : {}\".format(x_test.shape))\n",
    "print(\"y_test shape : {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indie-character",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - loss: 2.2240 - accuracy: 0.6200\n",
      "test_loss : 2.2240357398986816\n",
      "test_accuracy : 0.6200000047683716\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose = 2)\n",
    "\n",
    "print(\"test_loss : {}\".format(test_loss))\n",
    "print(\"test_accuracy : {}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
